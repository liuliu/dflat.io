{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"If you are familiar with Core Data or Realm , Dflat occupies the same space as these two in your application. Unlike these two, Dflat has a different set of features and makes very different trade-offs. These features and trade-offs are grounded from real-world experiences in writing some of the world largest apps. Dflat is also built from ground-up using Swift and hopefully, you will find it is natural to interact with in the Swift language. Features \u00b6 I've been writing different structured data persistence systems on mobile for the past a few years. Dflat is an accumulation of lessons-learned when building these proprietary systems. On iOS particular, the go-to choice long has been Core Data . It works, and is the internal data persistence mechanism for many system apps. But when deploying structured data persistence system to hundreds of millions mobile devices, there are certain challenges, both on the intrinsics of how data is persisted, and on a higher-level how the rest of the app interact with such system. The Dflat codebase is still in a very young stage. However, the underlying principles have been proving successful in other proprietary systems. Dflat implemented the following features in no particular order: The system returns immutable data objects that can be passed down to other systems (such as your view model generators); All queries and objects can be observed. Updates will be published through either callbacks or Combine framework; Mutation can only happen on separate threads that caller has little control over, thus, asynchronously; Data fetching can happen concurrently and synchronously on any thread by caller's choice; Strict serializable multi-writer / multi-reader mode is supported but users can choose single-writer (thus, trivially strict serializable) / multi-reader mode if they desire; Data queries are expressed with Swift code, and will be type-checked by the Swift compiler; Schema upgrades require no write-access to the underlying database (strict read-only is possible with SQLite 3.22 and above). Unlike Core Data , Dflat is built from ground-up with Swift. You can express your data model by taking full advantage of the Swift language. Thus, a native support for struct (product-type), enum (sum-type), with type-checked queries and observing with Combine .","title":"Home"},{"location":"#features","text":"I've been writing different structured data persistence systems on mobile for the past a few years. Dflat is an accumulation of lessons-learned when building these proprietary systems. On iOS particular, the go-to choice long has been Core Data . It works, and is the internal data persistence mechanism for many system apps. But when deploying structured data persistence system to hundreds of millions mobile devices, there are certain challenges, both on the intrinsics of how data is persisted, and on a higher-level how the rest of the app interact with such system. The Dflat codebase is still in a very young stage. However, the underlying principles have been proving successful in other proprietary systems. Dflat implemented the following features in no particular order: The system returns immutable data objects that can be passed down to other systems (such as your view model generators); All queries and objects can be observed. Updates will be published through either callbacks or Combine framework; Mutation can only happen on separate threads that caller has little control over, thus, asynchronously; Data fetching can happen concurrently and synchronously on any thread by caller's choice; Strict serializable multi-writer / multi-reader mode is supported but users can choose single-writer (thus, trivially strict serializable) / multi-reader mode if they desire; Data queries are expressed with Swift code, and will be type-checked by the Swift compiler; Schema upgrades require no write-access to the underlying database (strict read-only is possible with SQLite 3.22 and above). Unlike Core Data , Dflat is built from ground-up with Swift. You can express your data model by taking full advantage of the Swift language. Thus, a native support for struct (product-type), enum (sum-type), with type-checked queries and observing with Combine .","title":"Features"},{"location":"acknowledgement/","text":"Thanks Wouter van Oortmerssen for the flatbuffers serialization format, which introduced an excellent schema upgrade path. Thanks Dr. Hipp for SQLite implementation that enabled a reasonable foundational data persistence mechanism. Thanks Guillaume Lessard for the SwiftAtomics implementation, it is a shame that Swift doesn't have a good atomic primitives and we have to guess. Thanks Snap . While was employed there, I was able to build several structured data persistence mechanisms that become the predecessors of Dflat . Thanks Aaron Levine , for the idea of writing an open-source implementation of the proprietary system we developed together at Snap when I am in my retirement.","title":"Acknowledgement"},{"location":"benchmark/","text":"Benchmark \u00b6 CRUD \u00b6 Benchmark on structured data persistence system is notoriously hard. Dflat won't claim to be fastest. However, it strives to be predictable performant . What that means is there shouldn't be any pathological cases that the performance of Dflat degrades unexpectedly. It also means Dflat won't be surprisingly fast for some optimal cases. Following data are collected, and can be reproduced from: ./focus.py app:Benchmarks I compared mainly against Core Data, and listed numbers for FMDB and WCDB from WCDB Benchmark (from v1.0.8.2) to give a better overview of what you would expect from the test device. The test device is a iPhone 11 Pro with 64GB memory. A Disclaimer : you should take a grain of salt for any benchmark numbers. These numbers I presented here simply to demonstrate some pathological cases for frameworks involved. It shouldn't be taken out of this context. In practice, structured data persistence systems rarely are the bottle-neck. It is more important to understand how you use it rather than what's the raw numbers in a light-workload device looks like. The code for app:Benchmarks was compiled in Release mode ( --compilation-mode=opt ) with -whole-module-optimization on. The WCDB Benchmark was compiled in Release mode whatever that means in their project file. The benchmark itself is not peer-reviewed. In some cases, it represents the best case scenarios for these frameworks. In other cases, it represents the worst case scenarios. It is not designed to reflect real-world work-load. Rather, these benchmarks designed to reflect the framework's characteristics under extreme cases. First, we compared Dflat against Core Data on object insertions, fetching, updates and deletions. 10,000 objects are generated, with no index (only title indexed in Core Data). Fetching 1,667 Objects evaluated both frameworks on querying by non-indexed property. Update 10,000 Objects Individually evaluated updating different objects in separate transactions 10,000 times. Fetching 10,000 Objects Individually evaluated fetching different objects by title (indexed in Core Data and is the primary key in Dflat) 10,000 times. These are obviously not the best way of doing things (you should update objects in one big transaction, and fetch them in batch if possible), but these are the interesting pathological cases we discussed earlier. A proper way of doing multi-thread insertions / deletions in Core Data are considerably more tricky, I haven't got around to do that. The Multi-thread Insert 40,000 Objects and Multi-thread Delete 40,000 Objects are only for Dflat . Some of these numbers looks too good to be true. For example, on insertions, Dflat appears more than twice as fast as Core Data. Some of these numbers didn't make intuitive sense, why multi-thread insertions are slower? Putting it in perspective is important. The chart compared against numbers extracted from WCDB Benchmark (v1.0.8.2) without any modifications. It compares ops per seconds rather than time spent fetching 33,334 objects. Note that in WCDB Benchmark, Baseline Read did fetch all, which is the best case scenario in SQLite. It also compares a simple table with only two columns, a key and a blob payload (100 bytes). Multi-thread writes is indeed slower in our ideal case, because SQLite itself cannot execute writes concurrently. Thus, our multi-writer mode really just means these transaction closures can be executed concurrently. The writes still happen serially at SQLite layer. It is still beneficial because in real-world cases, we spend significant time in the transaction closure for data transformations, rather than SQLite writes. The ceiling for writes is much higher than what Dflat achieved. Again, WCDB represents an ideal case where you have only two columns. Dflat numbers in real-world would also be lower than what we had here, because we will have more indexes and objects with many fields, even arrays of data. Since Dflat doesn't introduce any optimizations for batch operations, it shouldn't be a surprise that Dflat performance scales linearly w.r.t. dataset size, as the follow chart will show. Change Subscription \u00b6 Every framework has slightly different design for how changes subscription works. Core Data implements this in two ways: NSFetchedResultsController delegate callbacks, and NSManagedObjectContextObjectsDidChange . From developer's perspective, NSFetchedResultsController can be interpreted as counter-part for FetchedResult subscription on Dflat side. Both supports making SQL-like queries and sending updates for the result set. You can build the Dflat object subscription mechanism in Core Data based on NSManagedObjectContextObjectsDidChange notification. For the purpose of being objective, I will simply observe the latency for NSManagedObjectContextObjectsDidChange notification when compare these two, assuming the underlying delivery to individual object subscription is a no-op. There are three parts of the benchmark: Subscribe changes to 1,000 fetched results, each observe exactly one object (fetched by the primary key). Subsequent transaction will update 10,000 objects, including these subscribed 1,000 objects. Measuring the latency from when saved, to the time when updates delivered. For Core Data, a child context of viewContext was set up, and the latency was measured before saving the child context, to the time it is delivered. This should be before data persisted ( viewContext.save() was called after child context saved). On Dflat side, this happens after data persisted. Subscribe changes to 1,000 fetched objects. Subsequent transaction will update 10,000 objects, including these subscribed 1,000 objects. Measuring the latency from when saved, to the time when updates delivered. For Core Data, NSManagedObjectContextObjectsDidChange was subscribed for the viewContext object. It measures the latency from before saving the child context, to the time notification was delivered. Subscribe changes to 1,000 fetched results, each observe around 1,000 objects (fetched by a range query). Subsequent transaction will update 10,000 objects, rotate all objects in each fetched results, while maintaining 1,000 objects per result. The measurement setup on Core Data is the same as 1. The number for both fetched results observation, especially on case 1, represents the most pathological case of them all. It is particularly troublesome for Dflat because fetching 1,000 objects from disk individually would take around 20 milliseconds. Thus, if we would take SQLite.swift approach of identifying whcih table changed and simply refetch every query on that table , we could end up more performant. Although for case 3, refetching from disk would definitely be slower (close to 6 seconds for 1,000 queries, each with 1,000 objects). From the benchmark, Core Data suffered similar problem, while being worse. Again, this is a extreme case. For mobile apps, you should only have handful of query subscriptions, with probably at most thousands of objects for each query, and unsubscribe changes as you navigate away to other pages. These extreme cases hardly realistic, you are not going to see 35-second stutter from Core Data just because there are 10,000 objects updated and you happen to have 1,000 table views need to be updated. In reality, subscribe to individual queries by primary key seems to be a big no-no. If you want to observe individual object, you should just subscribe individual object as case 2 shows. However, it does expose that our message-sorting-and-delivery mechanism not working as efficiently as we expected. Fundamentally, Dflat 's change subscription works best with incremental changes, because we evaluate every changed objects against all fetched request subscriptions related to that object. This design avoids trip to the disk on every transaction, but also relies on a reasonable implementation to evaluate every changed objects efficiently. A quick test shows that looping over 10,000 objects with 1,000 string equality evaluation in Swift takes about 30 milliseconds. Profile shows majority time was spent on objects retain / release and function calls for Swift runtime. There are two ways to improve: Current evaluation relies on Swift protocol with associated types. It seems certain Swift usage has higher runtime cost than others. Switching to a better linear scan, either with a interpreted VM or simply optimizing the evaluation procedure, would probably show 5 to 10x improvements. Algorithmically, it can be improved. Current implementation is naive in a way that we evaluate each object against each subscribed query. From the study of database implementation, we know accelerated data structures can be be helpful. Particularly, each FieldExpr in a query can be used to build a sorted set, Comparable queries can be accelerated with these sorted sets. Both are quite doable, while each has its own challenges. For 1, we need to wrestling with Swift runtime, and its behavior can be erratic at times for obvious gains to be possible. Because I am not intended to delegate parts to C, it makes all harder. For 2, while it is not hard to implement, we use 3-value logic internally (to support isNull / isNotNull queries), that means for every turn, we need to sort with UNKNOWN . Having a robust and correct such implementation means to have much more unit tests to feel comfortable. We also need to balance when to linear scan and when to use accelerated data structures because for small number of changes, linear scan could be faster from previous empirical studies.","title":"Benchmark"},{"location":"benchmark/#benchmark","text":"","title":"Benchmark"},{"location":"benchmark/#crud","text":"Benchmark on structured data persistence system is notoriously hard. Dflat won't claim to be fastest. However, it strives to be predictable performant . What that means is there shouldn't be any pathological cases that the performance of Dflat degrades unexpectedly. It also means Dflat won't be surprisingly fast for some optimal cases. Following data are collected, and can be reproduced from: ./focus.py app:Benchmarks I compared mainly against Core Data, and listed numbers for FMDB and WCDB from WCDB Benchmark (from v1.0.8.2) to give a better overview of what you would expect from the test device. The test device is a iPhone 11 Pro with 64GB memory. A Disclaimer : you should take a grain of salt for any benchmark numbers. These numbers I presented here simply to demonstrate some pathological cases for frameworks involved. It shouldn't be taken out of this context. In practice, structured data persistence systems rarely are the bottle-neck. It is more important to understand how you use it rather than what's the raw numbers in a light-workload device looks like. The code for app:Benchmarks was compiled in Release mode ( --compilation-mode=opt ) with -whole-module-optimization on. The WCDB Benchmark was compiled in Release mode whatever that means in their project file. The benchmark itself is not peer-reviewed. In some cases, it represents the best case scenarios for these frameworks. In other cases, it represents the worst case scenarios. It is not designed to reflect real-world work-load. Rather, these benchmarks designed to reflect the framework's characteristics under extreme cases. First, we compared Dflat against Core Data on object insertions, fetching, updates and deletions. 10,000 objects are generated, with no index (only title indexed in Core Data). Fetching 1,667 Objects evaluated both frameworks on querying by non-indexed property. Update 10,000 Objects Individually evaluated updating different objects in separate transactions 10,000 times. Fetching 10,000 Objects Individually evaluated fetching different objects by title (indexed in Core Data and is the primary key in Dflat) 10,000 times. These are obviously not the best way of doing things (you should update objects in one big transaction, and fetch them in batch if possible), but these are the interesting pathological cases we discussed earlier. A proper way of doing multi-thread insertions / deletions in Core Data are considerably more tricky, I haven't got around to do that. The Multi-thread Insert 40,000 Objects and Multi-thread Delete 40,000 Objects are only for Dflat . Some of these numbers looks too good to be true. For example, on insertions, Dflat appears more than twice as fast as Core Data. Some of these numbers didn't make intuitive sense, why multi-thread insertions are slower? Putting it in perspective is important. The chart compared against numbers extracted from WCDB Benchmark (v1.0.8.2) without any modifications. It compares ops per seconds rather than time spent fetching 33,334 objects. Note that in WCDB Benchmark, Baseline Read did fetch all, which is the best case scenario in SQLite. It also compares a simple table with only two columns, a key and a blob payload (100 bytes). Multi-thread writes is indeed slower in our ideal case, because SQLite itself cannot execute writes concurrently. Thus, our multi-writer mode really just means these transaction closures can be executed concurrently. The writes still happen serially at SQLite layer. It is still beneficial because in real-world cases, we spend significant time in the transaction closure for data transformations, rather than SQLite writes. The ceiling for writes is much higher than what Dflat achieved. Again, WCDB represents an ideal case where you have only two columns. Dflat numbers in real-world would also be lower than what we had here, because we will have more indexes and objects with many fields, even arrays of data. Since Dflat doesn't introduce any optimizations for batch operations, it shouldn't be a surprise that Dflat performance scales linearly w.r.t. dataset size, as the follow chart will show.","title":"CRUD"},{"location":"benchmark/#change-subscription","text":"Every framework has slightly different design for how changes subscription works. Core Data implements this in two ways: NSFetchedResultsController delegate callbacks, and NSManagedObjectContextObjectsDidChange . From developer's perspective, NSFetchedResultsController can be interpreted as counter-part for FetchedResult subscription on Dflat side. Both supports making SQL-like queries and sending updates for the result set. You can build the Dflat object subscription mechanism in Core Data based on NSManagedObjectContextObjectsDidChange notification. For the purpose of being objective, I will simply observe the latency for NSManagedObjectContextObjectsDidChange notification when compare these two, assuming the underlying delivery to individual object subscription is a no-op. There are three parts of the benchmark: Subscribe changes to 1,000 fetched results, each observe exactly one object (fetched by the primary key). Subsequent transaction will update 10,000 objects, including these subscribed 1,000 objects. Measuring the latency from when saved, to the time when updates delivered. For Core Data, a child context of viewContext was set up, and the latency was measured before saving the child context, to the time it is delivered. This should be before data persisted ( viewContext.save() was called after child context saved). On Dflat side, this happens after data persisted. Subscribe changes to 1,000 fetched objects. Subsequent transaction will update 10,000 objects, including these subscribed 1,000 objects. Measuring the latency from when saved, to the time when updates delivered. For Core Data, NSManagedObjectContextObjectsDidChange was subscribed for the viewContext object. It measures the latency from before saving the child context, to the time notification was delivered. Subscribe changes to 1,000 fetched results, each observe around 1,000 objects (fetched by a range query). Subsequent transaction will update 10,000 objects, rotate all objects in each fetched results, while maintaining 1,000 objects per result. The measurement setup on Core Data is the same as 1. The number for both fetched results observation, especially on case 1, represents the most pathological case of them all. It is particularly troublesome for Dflat because fetching 1,000 objects from disk individually would take around 20 milliseconds. Thus, if we would take SQLite.swift approach of identifying whcih table changed and simply refetch every query on that table , we could end up more performant. Although for case 3, refetching from disk would definitely be slower (close to 6 seconds for 1,000 queries, each with 1,000 objects). From the benchmark, Core Data suffered similar problem, while being worse. Again, this is a extreme case. For mobile apps, you should only have handful of query subscriptions, with probably at most thousands of objects for each query, and unsubscribe changes as you navigate away to other pages. These extreme cases hardly realistic, you are not going to see 35-second stutter from Core Data just because there are 10,000 objects updated and you happen to have 1,000 table views need to be updated. In reality, subscribe to individual queries by primary key seems to be a big no-no. If you want to observe individual object, you should just subscribe individual object as case 2 shows. However, it does expose that our message-sorting-and-delivery mechanism not working as efficiently as we expected. Fundamentally, Dflat 's change subscription works best with incremental changes, because we evaluate every changed objects against all fetched request subscriptions related to that object. This design avoids trip to the disk on every transaction, but also relies on a reasonable implementation to evaluate every changed objects efficiently. A quick test shows that looping over 10,000 objects with 1,000 string equality evaluation in Swift takes about 30 milliseconds. Profile shows majority time was spent on objects retain / release and function calls for Swift runtime. There are two ways to improve: Current evaluation relies on Swift protocol with associated types. It seems certain Swift usage has higher runtime cost than others. Switching to a better linear scan, either with a interpreted VM or simply optimizing the evaluation procedure, would probably show 5 to 10x improvements. Algorithmically, it can be improved. Current implementation is naive in a way that we evaluate each object against each subscribed query. From the study of database implementation, we know accelerated data structures can be be helpful. Particularly, each FieldExpr in a query can be used to build a sorted set, Comparable queries can be accelerated with these sorted sets. Both are quite doable, while each has its own challenges. For 1, we need to wrestling with Swift runtime, and its behavior can be erratic at times for obvious gains to be possible. Because I am not intended to delegate parts to C, it makes all harder. For 2, while it is not hard to implement, we use 3-value logic internally (to support isNull / isNotNull queries), that means for every turn, we need to sort with UNKNOWN . Having a robust and correct such implementation means to have much more unit tests to feel comfortable. We also need to balance when to linear scan and when to use accelerated data structures because for small number of changes, linear scan could be faster from previous empirical studies.","title":"Change Subscription"},{"location":"getting-started/","text":"Dflat consists two parts: dflatc compiler that takes a flatbuffers schema and generate Swift code from it; Dflat runtime with very minimal API footprint to interact with. The Dflat runtime uses SQLite as the storage backend. The design itself can support other backends such as libmdbx in the future. The only hard dependency is flatbuffers. To use Dflat , you should first use dflatc compiler to generate data model from flatbuffers schema, include the generated code in your project, and then use Dflat runtime to interact with the data models. Installation \u00b6 Dflat at the moment requires Bazel . To be more precise, Dflat runtime can be installed with either Swift Package Manager or Bazel. But the dflatc compiler requires Bazel to build relevant parts. You can install Bazel on macOS following this guide . After that, you can use dflatc compiler with ./dflatc.py --help You can then proceed to add Dflat runtime either with Swift Package Manager or Bazel. With Swift Package Manager: . package ( name : \"Dflat\" , url : \"https://github.com/liuliu/dflat.git\" , . branch ( \"unstable\" )) Example \u00b6 Assuming you have a post.fbs file somewhere look like this: enum Color : byte { Red = 0 , Green , Blue = 2 } table TextContent { text : string ; } table ImageContent { images : [ string ] ; } union Content { TextContent , ImageContent } table Post { title : string ( primary ); // This is the primary key color : Color ; tag : string ; priority : int ( indexed ); // This property is indexed content : Content ; } root_type Post ; // This is important , it says the Post object will be the one Dflat manages . You can then use dflatc compiler to generate code from the schema: ./dflatc.py -o ../PostExample ../PostExample/post.fbs If everything checks out, you should see 4 files generated in ../PostExample directory: post_generated.swift , post_data_model_generated.swift , post_mutating_generated.swift , post_query_generated.swift . Adding them to your project. Now you can do basic Create-Read-Update-Delete (CRUD) operations on the Post object. import Dflat import SQLiteDflat let dflat = SQLiteWorkspace ( filePath : filePath , fileProtectionLevel : . noProtection ) Create: var createdPost : Post ? = nil dflat . performChanges ([ Post . self ], changesHandler : { ( txnContext ) in let creationRequest = PostChangeRequest . creationRequest () creationRequest . title = \"first post\" creationRequest . color = . red creationRequest . content = . textContent ( TextContent ( text : \"This is my very first post!\" )) guard let inserted = try ? txnContent . submit ( creationRequest ) else { return } // Alternatively, you can use txnContent.try(submit: creationRequest) which won't return any result and do \"reasonable\" error handling. if case let . inserted ( post ) = inserted { createdPost = post } }) { succeed in // Transaction Done } Read: let posts = dflat . fetch ( for : Post . self ). where ( Post . title == \"first post\" ) Update: dflat . performChanges ([ Post . self ], changesHandler : { ( txnContext ) in let post = posts [ 0 ] let changeRequest = PostChangeRequest . changeRequest ( post ) changeRequest . color = . green txnContent . try ( submit : changeRequest ) }) { succeed in // Transaction Done } Delete: dflat . performChanges ([ Post . self ], changesHandler : { ( txnContext ) in let post = posts [ 0 ] let deletionRequest = PostChangeRequest . deletionRequest ( post ) txnContent . try ( submit : deletionRequest ) }) { succeed in // Transaction Done } You can subscribe changes to either a query, or an object. For an object, the subscription ends when the object was deleted. For queries, the subscription won't complete unless cancelled. There are two sets of APIs for this, one is vanilla callback-based, the other is based on Combine . I will show the Combine one here. Subscribe a live query: let cancellable = dflat . publisher ( for : Post . self ) . where ( Post . color == . red , orderBy : [ Post . priority . descending ]) . subscribe ( on : DispatchQueue . global ()) . sink { posts in print ( posts ) } Subscribe to an object: let cancellable = dflat . pulisher ( for : posts [ 0 ]) . subscribe ( on : DispatchQueue . global ()) . sink { post in switch post { case . updated ( newPost ): print ( newPost ) case . deleted : print ( \"deleted, this is completed.\" ) } }","title":"Getting Started"},{"location":"getting-started/#installation","text":"Dflat at the moment requires Bazel . To be more precise, Dflat runtime can be installed with either Swift Package Manager or Bazel. But the dflatc compiler requires Bazel to build relevant parts. You can install Bazel on macOS following this guide . After that, you can use dflatc compiler with ./dflatc.py --help You can then proceed to add Dflat runtime either with Swift Package Manager or Bazel. With Swift Package Manager: . package ( name : \"Dflat\" , url : \"https://github.com/liuliu/dflat.git\" , . branch ( \"unstable\" ))","title":"Installation"},{"location":"getting-started/#example","text":"Assuming you have a post.fbs file somewhere look like this: enum Color : byte { Red = 0 , Green , Blue = 2 } table TextContent { text : string ; } table ImageContent { images : [ string ] ; } union Content { TextContent , ImageContent } table Post { title : string ( primary ); // This is the primary key color : Color ; tag : string ; priority : int ( indexed ); // This property is indexed content : Content ; } root_type Post ; // This is important , it says the Post object will be the one Dflat manages . You can then use dflatc compiler to generate code from the schema: ./dflatc.py -o ../PostExample ../PostExample/post.fbs If everything checks out, you should see 4 files generated in ../PostExample directory: post_generated.swift , post_data_model_generated.swift , post_mutating_generated.swift , post_query_generated.swift . Adding them to your project. Now you can do basic Create-Read-Update-Delete (CRUD) operations on the Post object. import Dflat import SQLiteDflat let dflat = SQLiteWorkspace ( filePath : filePath , fileProtectionLevel : . noProtection ) Create: var createdPost : Post ? = nil dflat . performChanges ([ Post . self ], changesHandler : { ( txnContext ) in let creationRequest = PostChangeRequest . creationRequest () creationRequest . title = \"first post\" creationRequest . color = . red creationRequest . content = . textContent ( TextContent ( text : \"This is my very first post!\" )) guard let inserted = try ? txnContent . submit ( creationRequest ) else { return } // Alternatively, you can use txnContent.try(submit: creationRequest) which won't return any result and do \"reasonable\" error handling. if case let . inserted ( post ) = inserted { createdPost = post } }) { succeed in // Transaction Done } Read: let posts = dflat . fetch ( for : Post . self ). where ( Post . title == \"first post\" ) Update: dflat . performChanges ([ Post . self ], changesHandler : { ( txnContext ) in let post = posts [ 0 ] let changeRequest = PostChangeRequest . changeRequest ( post ) changeRequest . color = . green txnContent . try ( submit : changeRequest ) }) { succeed in // Transaction Done } Delete: dflat . performChanges ([ Post . self ], changesHandler : { ( txnContext ) in let post = posts [ 0 ] let deletionRequest = PostChangeRequest . deletionRequest ( post ) txnContent . try ( submit : deletionRequest ) }) { succeed in // Transaction Done } You can subscribe changes to either a query, or an object. For an object, the subscription ends when the object was deleted. For queries, the subscription won't complete unless cancelled. There are two sets of APIs for this, one is vanilla callback-based, the other is based on Combine . I will show the Combine one here. Subscribe a live query: let cancellable = dflat . publisher ( for : Post . self ) . where ( Post . color == . red , orderBy : [ Post . priority . descending ]) . subscribe ( on : DispatchQueue . global ()) . sink { posts in print ( posts ) } Subscribe to an object: let cancellable = dflat . pulisher ( for : posts [ 0 ]) . subscribe ( on : DispatchQueue . global ()) . sink { post in switch post { case . updated ( newPost ): print ( newPost ) case . deleted : print ( \"deleted, this is completed.\" ) } }","title":"Example"},{"location":"namespace/","text":"Namespace \u00b6 Dflat schema supports namespace, as does flatbuffers schema. However, because Swift doesn't really support proper namespace, the namespace implementation relies on public enum and extensions. Thus, if you have namespace: namespace Evolution . V1 ; table Post { title : string ( primary ); } root_type Post ; You have to declare the namespace yourself. In your project, you need to have a Swift file contains following: public enum Evolution { public enum V1 { } } And it will work. You can then access the Post object through Evolution.V1.Post or typealias Post = Evolution.V1.Post .","title":"Namespace"},{"location":"namespace/#namespace","text":"Dflat schema supports namespace, as does flatbuffers schema. However, because Swift doesn't really support proper namespace, the namespace implementation relies on public enum and extensions. Thus, if you have namespace: namespace Evolution . V1 ; table Post { title : string ( primary ); } root_type Post ; You have to declare the namespace yourself. In your project, you need to have a Swift file contains following: public enum Evolution { public enum V1 { } } And it will work. You can then access the Post object through Evolution.V1.Post or typealias Post = Evolution.V1.Post .","title":"Namespace"},{"location":"runtime-api/","text":"Runtime API \u00b6 Dflat runtime has very minimal API footprint. There are about 15 APIs in total from 2 objects. Transactions \u00b6 func Workspace . performChanges ( _ transactionalObjectTypes : [ Any . Type ], changesHandler : @ escaping ( _ transactionContext : TransactionContext ) -> Void , completionHandler : (( _ success : Bool ) -> Void )? = nil ) The API takes a changesHandler closure, where you can perform transactions such as object creations, updates or deletions. These mutations are performed through ChangeRequest objects. The first parameter specifies relevant object you are going to transact with. If you read or update any objects that is not specified here, an assertion will be triggered. When the transaction is done, the completionHandler closure will be triggered, and it will let you know whether the transaction is successful or not. The transaction will be performed in a background thread, exactly which one shouldn't be your concern. Two different objects can have transactions performed concurrently, it follows strict serializable protocol in that case. func TransactionContext . submit ( _ changeRequest : ChangeRequest ) throws -> UpdatedObject func TransactionContext . try ( submit : ChangeRequest ) -> UpdatedObject ? func TransactionContext . abort () -> Bool You can interact with Dflat with above APIs in a transaction. It handles data mutations through submit . Note that errors are possible. For example, if you created an object with the same primary key twice (you should use upsertRequest if this is expected). try(submit: method simplified the try? submit dance in case you don't want to know the returned value. It will fatal if there are conflict primary keys, otherwise will swallow other types of errors (such as disk full). When encountered any other types of errors, Dflat will simply fail the whole transaction. abort method will explicitly abort a transaction. All submissions before and after this call will have no effect. Data Fetching \u00b6 func Workspace . fetch ( for ofType : Element . Type ). where ( ElementQuery , limit = . noLimit , orderBy = []) -> FetchedResult < Element > func Workspace . fetch ( for ofType : Element . Type ). all ( limit = . noLimit , orderBy = []) -> FetchedResult < Element > func Workspace . fetchWithinASnapshot < T >( _ : () -> T ) -> T Data fetching happens synchronously. You can specify conditions in the where clause, such as Post.title == \"first post\" or Post.priority > 100 && Post.color == .red . The returned FetchedResult<Element> acts pretty much like an array. The object itself ( Element ) is immutable, thus, either the object or the FetchedResult<Element> is safe to pass around between threads. fetchWithinASnapshot provides a consistent view if you are going to fetch multiple objects: let result = dflat . fetchWithinASnapshot { () -> ( firstPost : FetchedResult < Post >, highPriPosts : FetchedResult < Post >) in let firstPost = dflat . fetch ( for : Post . self ). where ( Post . title == \"first post\" ) let highPriPosts = dflat . fetch ( for : Post . self ). where ( Post . priority > 100 && Post . color == . red ) return ( firstPost , highPriPosts ) } This is needed because Dflat can do transactions in between fetch for firstPost and highPriPosts . The fetchWithinASnapshot won't stop that transaction, but will make sure it only observe the view from fetching for firstPost . Data Subscription \u00b6 func Workspace . subscribe < Element : Equatable >( fetchedResult : FetchedResult < Element >, changeHandler : @ escaping ( _ : FetchedResult < Element >) -> Void ) -> Subscription func Workspace . subscribe < Element : Equatable >( object : Element , changeHandler : @ escaping ( _ : SubscribedObject < Element >) -> Void ) -> Subscription The above are the native subscription APIs. It subscribes changes to either a fetchedResult or an object. For object, it will end when object deleted. The subscription is triggered before a completionHandler on a transaction triggered. func Workspace . publisher < Element : Equatable >( for : Element ) -> AtomPublisher < Element > func Workspace . publisher < Element : Equatable >( for : FetchedResult < Element >) -> FetchedResultPublisher < Element > func Workspace . publisher < Element : Equatable >( for : Element . Type ). where ( ElementQuery , limit = . noLimit , orderBy = []) -> QueryPublisher < Element > func Workspace . publisher < Element : Equatable >( for : Element . Type ). all ( limit = . noLimit , orderBy = []) -> QueryPublisher < Element > These are the Combine counter-parts. Besides subscribing to objects or fetchedResult , it can also subscribe to a query directly. What happens under the hood is the query will be made upon subscribe (hence, on whichever queue you provided if you did subscribe(on: ), and subscribe the fetchedResult from then on. Close \u00b6 func Workspace . shutdown ( completion : (() -> Void )? = nil ) This will trigger the Dflat shutdown. All transactions made to Dflat after this call will fail. Transactions initiated before this will finish normally. Data fetching after this will return empty results. Any data fetching triggered before this call will finish normally, hence the completion part. The completion closure, if supplied, will be called once all transactions and data fetching initiated before shutdown finish.","title":"Runtime API"},{"location":"runtime-api/#runtime-api","text":"Dflat runtime has very minimal API footprint. There are about 15 APIs in total from 2 objects.","title":"Runtime API"},{"location":"runtime-api/#transactions","text":"func Workspace . performChanges ( _ transactionalObjectTypes : [ Any . Type ], changesHandler : @ escaping ( _ transactionContext : TransactionContext ) -> Void , completionHandler : (( _ success : Bool ) -> Void )? = nil ) The API takes a changesHandler closure, where you can perform transactions such as object creations, updates or deletions. These mutations are performed through ChangeRequest objects. The first parameter specifies relevant object you are going to transact with. If you read or update any objects that is not specified here, an assertion will be triggered. When the transaction is done, the completionHandler closure will be triggered, and it will let you know whether the transaction is successful or not. The transaction will be performed in a background thread, exactly which one shouldn't be your concern. Two different objects can have transactions performed concurrently, it follows strict serializable protocol in that case. func TransactionContext . submit ( _ changeRequest : ChangeRequest ) throws -> UpdatedObject func TransactionContext . try ( submit : ChangeRequest ) -> UpdatedObject ? func TransactionContext . abort () -> Bool You can interact with Dflat with above APIs in a transaction. It handles data mutations through submit . Note that errors are possible. For example, if you created an object with the same primary key twice (you should use upsertRequest if this is expected). try(submit: method simplified the try? submit dance in case you don't want to know the returned value. It will fatal if there are conflict primary keys, otherwise will swallow other types of errors (such as disk full). When encountered any other types of errors, Dflat will simply fail the whole transaction. abort method will explicitly abort a transaction. All submissions before and after this call will have no effect.","title":"Transactions"},{"location":"runtime-api/#data-fetching","text":"func Workspace . fetch ( for ofType : Element . Type ). where ( ElementQuery , limit = . noLimit , orderBy = []) -> FetchedResult < Element > func Workspace . fetch ( for ofType : Element . Type ). all ( limit = . noLimit , orderBy = []) -> FetchedResult < Element > func Workspace . fetchWithinASnapshot < T >( _ : () -> T ) -> T Data fetching happens synchronously. You can specify conditions in the where clause, such as Post.title == \"first post\" or Post.priority > 100 && Post.color == .red . The returned FetchedResult<Element> acts pretty much like an array. The object itself ( Element ) is immutable, thus, either the object or the FetchedResult<Element> is safe to pass around between threads. fetchWithinASnapshot provides a consistent view if you are going to fetch multiple objects: let result = dflat . fetchWithinASnapshot { () -> ( firstPost : FetchedResult < Post >, highPriPosts : FetchedResult < Post >) in let firstPost = dflat . fetch ( for : Post . self ). where ( Post . title == \"first post\" ) let highPriPosts = dflat . fetch ( for : Post . self ). where ( Post . priority > 100 && Post . color == . red ) return ( firstPost , highPriPosts ) } This is needed because Dflat can do transactions in between fetch for firstPost and highPriPosts . The fetchWithinASnapshot won't stop that transaction, but will make sure it only observe the view from fetching for firstPost .","title":"Data Fetching"},{"location":"runtime-api/#data-subscription","text":"func Workspace . subscribe < Element : Equatable >( fetchedResult : FetchedResult < Element >, changeHandler : @ escaping ( _ : FetchedResult < Element >) -> Void ) -> Subscription func Workspace . subscribe < Element : Equatable >( object : Element , changeHandler : @ escaping ( _ : SubscribedObject < Element >) -> Void ) -> Subscription The above are the native subscription APIs. It subscribes changes to either a fetchedResult or an object. For object, it will end when object deleted. The subscription is triggered before a completionHandler on a transaction triggered. func Workspace . publisher < Element : Equatable >( for : Element ) -> AtomPublisher < Element > func Workspace . publisher < Element : Equatable >( for : FetchedResult < Element >) -> FetchedResultPublisher < Element > func Workspace . publisher < Element : Equatable >( for : Element . Type ). where ( ElementQuery , limit = . noLimit , orderBy = []) -> QueryPublisher < Element > func Workspace . publisher < Element : Equatable >( for : Element . Type ). all ( limit = . noLimit , orderBy = []) -> QueryPublisher < Element > These are the Combine counter-parts. Besides subscribing to objects or fetchedResult , it can also subscribe to a query directly. What happens under the hood is the query will be made upon subscribe (hence, on whichever queue you provided if you did subscribe(on: ), and subscribe the fetchedResult from then on.","title":"Data Subscription"},{"location":"runtime-api/#close","text":"func Workspace . shutdown ( completion : (() -> Void )? = nil ) This will trigger the Dflat shutdown. All transactions made to Dflat after this call will fail. Transactions initiated before this will finish normally. Data fetching after this will return empty results. Any data fetching triggered before this call will finish normally, hence the completion part. The completion closure, if supplied, will be called once all transactions and data fetching initiated before shutdown finish.","title":"Close"},{"location":"schema/","text":"Schema Evolution \u00b6 The schema evolution in Dflat Follows exact with flatbuffers. The only exception is that you cannot add more primary keys or change primary key to a different property once it is selected. Otherwise, you are free to add or remove indexes, rename properties. Properties to be removed should be marked as deprecated , new properties should be appended to the end of the table, and you should never change the type of a property. There is no need for versioning as long as you follow the schema evolution path. Because the schema is maintained by flatbuffers, not SQLite, there is no disk ops required for schema upgrade. Schema upgrade failures due to lack of disk space or prolonged schema upgrade time due to pathological cases won't be a thing with Dflat .","title":"Schema Evolution"},{"location":"schema/#schema-evolution","text":"The schema evolution in Dflat Follows exact with flatbuffers. The only exception is that you cannot add more primary keys or change primary key to a different property once it is selected. Otherwise, you are free to add or remove indexes, rename properties. Properties to be removed should be marked as deprecated , new properties should be appended to the end of the table, and you should never change the type of a property. There is no need for versioning as long as you follow the schema evolution path. Because the schema is maintained by flatbuffers, not SQLite, there is no disk ops required for schema upgrade. Schema upgrade failures due to lack of disk space or prolonged schema upgrade time due to pathological cases won't be a thing with Dflat .","title":"Schema Evolution"},{"location":"notes/mwmr/","text":"MWMR \u00b6 MWMR (multi-writer / multi-reader) is a desirable mode for local databases, the exactly one Dflat focuses on. However, if you desire no conflict for a transaction, the multi-writer / multi-reader degrades to single-writer per table. This is what Dflat tries to offer. In simple words, Dflat makes sure each transaction closure operates on the same table executed serially. If they operate on different tables, they can be executed concurrently. That is the fundamental reason why you have to pledge which object types you want to operate upfront in performChanges(_:) . This is how strict serializable claim derived. Is it really multi-writer with full concurrency, if we operate on different tables at the same time? Unfortunately, the answer is no, at the moment, with SQLite backend. It is related to the particular mode we operate with SQLite, the \"Write-Ahead Logging\" . To be precise, Dflat transaction closures for different tables operate concurrently, that fetch new objects, create new change requests, up until the first change request submitted. The first transaction closure that submitted the first change request will hold an exclusive lock to the end of that transaction closure, even if after the first submission, it only reads. Everyone else when submitting their change request, will be blocked until the first transaction closure finishes. This is undesirable, but necessary due to SQLite WAL implementation. SQLite WAL implementation uses one WAL file, and writes in a transaction simply append to that log file. A rollback for a transaction simply means truncate the log file to an earlier point. Thus, once a write in a transaction happen, no writes from different transactions can be appended until the first transaction committed. Interleaving writes from different transactions, even for different tables, will make the rollback logic complicated (you almost certainly need to rewrite the log, which is a big no-no from original design perspective). Alternatively, we can use one database file per table. However, this makes cross table transaction non-atomic . Fundamentally, this can only be fixed at SQLite level, possibly with multi-WAL files, which IMHO would be a no-go for SQLite. Another alternative is to investigate other CoW (Copy-on-Write) data structure based databases, such as libmdbx . Since these databases are key-value based, we also need to implement query execution logic for indexed queries ourselves rather than just generate SQL queries. This is simple enough and quite doable. But back to the MWMR situation we are trying to solve, I need to read more about how CoW data structure works and how it handles transaction rollbacks for cross table transactions (in key-value case, cross keyspace transactions) to make sure it is a viable long-term solution. There exists an effective but simple solution : make sure in a transaction closure, you do all data transformations upfront, create or mutate all change requests, and then submit them towards the end of the transaction closure. It probably works best for everyone this way.","title":"MWMR"},{"location":"notes/mwmr/#mwmr","text":"MWMR (multi-writer / multi-reader) is a desirable mode for local databases, the exactly one Dflat focuses on. However, if you desire no conflict for a transaction, the multi-writer / multi-reader degrades to single-writer per table. This is what Dflat tries to offer. In simple words, Dflat makes sure each transaction closure operates on the same table executed serially. If they operate on different tables, they can be executed concurrently. That is the fundamental reason why you have to pledge which object types you want to operate upfront in performChanges(_:) . This is how strict serializable claim derived. Is it really multi-writer with full concurrency, if we operate on different tables at the same time? Unfortunately, the answer is no, at the moment, with SQLite backend. It is related to the particular mode we operate with SQLite, the \"Write-Ahead Logging\" . To be precise, Dflat transaction closures for different tables operate concurrently, that fetch new objects, create new change requests, up until the first change request submitted. The first transaction closure that submitted the first change request will hold an exclusive lock to the end of that transaction closure, even if after the first submission, it only reads. Everyone else when submitting their change request, will be blocked until the first transaction closure finishes. This is undesirable, but necessary due to SQLite WAL implementation. SQLite WAL implementation uses one WAL file, and writes in a transaction simply append to that log file. A rollback for a transaction simply means truncate the log file to an earlier point. Thus, once a write in a transaction happen, no writes from different transactions can be appended until the first transaction committed. Interleaving writes from different transactions, even for different tables, will make the rollback logic complicated (you almost certainly need to rewrite the log, which is a big no-no from original design perspective). Alternatively, we can use one database file per table. However, this makes cross table transaction non-atomic . Fundamentally, this can only be fixed at SQLite level, possibly with multi-WAL files, which IMHO would be a no-go for SQLite. Another alternative is to investigate other CoW (Copy-on-Write) data structure based databases, such as libmdbx . Since these databases are key-value based, we also need to implement query execution logic for indexed queries ourselves rather than just generate SQL queries. This is simple enough and quite doable. But back to the MWMR situation we are trying to solve, I need to read more about how CoW data structure works and how it handles transaction rollbacks for cross table transactions (in key-value case, cross keyspace transactions) to make sure it is a viable long-term solution. There exists an effective but simple solution : make sure in a transaction closure, you do all data transformations upfront, create or mutate all change requests, and then submit them towards the end of the transaction closure. It probably works best for everyone this way.","title":"MWMR"},{"location":"notes/rowid/","text":"Rowid & ChangesTimestamp \u00b6 There are two Int64 abstractions leaked in Dflat : rowid and changes timestamp. I will discuss what them are, and why they leaked. Both of them are powerful enough to make the abstraction leakage worthy. Rowid \u00b6 This is leaked from underlying SQLite backend. We elected for rowid to be a 64-bit monotonically increment integer that uniquely identify an object. Because it is monotonically incremented, old rowid won't be reused by new object. This helps in multiple fronts: We can uniquely identify an object, even if it is deleted later, without worrying a new object could occupy the same rowid; We could quickly check whether an index (we index a field with a different table) up-to-date or not by comparing MAX(rowid) from both main table and the index table. This is a very cheap operation and free of problems such as object deletion (if we naively use COUNT(rowid) , it could match because the index table hasn't caught up with main table while main table deleted some items). If in the future, we moved to the other backends, rowid as a concept could still survive, due to benefits listed above. ChangesTimestamp \u00b6 This is not a persisted property. It is an monotonically increment integer increments every time a transaction committed. Any data fetch will associate a changesTimestamp atomically fetched. This helps quickly check whether an object or a fetched result could change after the time when it is fetched. This is used for changes subscription. If the atomic load / store becomes a bottle-neck, we may need to re-think how we do this in the future, possibly store them in thread-local manner and only propagate updates once for a while. It is unlikely though.","title":"Rowid & ChangesTimestamp"},{"location":"notes/rowid/#rowid-changestimestamp","text":"There are two Int64 abstractions leaked in Dflat : rowid and changes timestamp. I will discuss what them are, and why they leaked. Both of them are powerful enough to make the abstraction leakage worthy.","title":"Rowid &amp; ChangesTimestamp"},{"location":"notes/rowid/#rowid","text":"This is leaked from underlying SQLite backend. We elected for rowid to be a 64-bit monotonically increment integer that uniquely identify an object. Because it is monotonically incremented, old rowid won't be reused by new object. This helps in multiple fronts: We can uniquely identify an object, even if it is deleted later, without worrying a new object could occupy the same rowid; We could quickly check whether an index (we index a field with a different table) up-to-date or not by comparing MAX(rowid) from both main table and the index table. This is a very cheap operation and free of problems such as object deletion (if we naively use COUNT(rowid) , it could match because the index table hasn't caught up with main table while main table deleted some items). If in the future, we moved to the other backends, rowid as a concept could still survive, due to benefits listed above.","title":"Rowid"},{"location":"notes/rowid/#changestimestamp","text":"This is not a persisted property. It is an monotonically increment integer increments every time a transaction committed. Any data fetch will associate a changesTimestamp atomically fetched. This helps quickly check whether an object or a fetched result could change after the time when it is fetched. This is used for changes subscription. If the atomic load / store becomes a bottle-neck, we may need to re-think how we do this in the future, possibly store them in thread-local manner and only propagate updates once for a while. It is unlikely though.","title":"ChangesTimestamp"},{"location":"notes/trade-offs/","text":"Features & Trade Offs \u00b6 If you are familiar with Core Data or Realm , you may find Dflat rather different. The mutation in Core Data is pretty straight-forward: just assign new values to properties on a subclass of NSManagedObject . In Dflat , you need to performChanges(_:) , get change request, and then submit to a TransactionContext . It is quite a dance. In return though, you can pass the fetched objects around, without worrying whether you need to object.MR_inContext() . This, coupled with change subscription mechanism, makes one-way data flow design straight-forward. On your component, you simply need to subscribe the object and update the UI accordingly. On your action handler, you call performChanges(_:) and submit changes to Dflat without worrying about when update will be triggered. In real-world, this can be a bit more complicated because you want to merge some in-memory states when data propagate to the UI. Thus, the subscriber of object changes likely will be some components sit in the middle, i.e. a view model generator. This Combine s nicely with Rx programming paradigm. It also feels limiting that you don't control which thread the mutation happens. Dflat does expose some kind of control to you. You can set the targetQueue for SQLiteWorkspace . Anything beyond that, can only bite you in longer-term. You don't really want any of your queue to be blocked because some data persistence happening. As long as there is no coroutine support from Swift side, a completion callback is a necessary evil. Another criticism, which IMHO is more legit, is the lack of projection support. You can absolutely join tables by cleverly use fetchWithinASnapshot . But projection, i.e. only selecting a few columns to fetch, can be helpful, especially on Android, where object creation is more expensive (it doesn't help much on data fetching from disk unless all you fetch is covered by index ). This is doable thanks to flatbuffers' zero-copy implementation. However, it requires a rather different syntax on the IDL (interface description language) to describe the projection concisely. Something like: table Title <- BlogPost { permalink <- BlogPost.permalink title <- BlogPost.title } May work, and we can generate the corresponding Title object. It just diverges too much from flatbuffers schema to justify the learning curve at the moment.","title":"Features & Trade Offs"},{"location":"notes/trade-offs/#features-trade-offs","text":"If you are familiar with Core Data or Realm , you may find Dflat rather different. The mutation in Core Data is pretty straight-forward: just assign new values to properties on a subclass of NSManagedObject . In Dflat , you need to performChanges(_:) , get change request, and then submit to a TransactionContext . It is quite a dance. In return though, you can pass the fetched objects around, without worrying whether you need to object.MR_inContext() . This, coupled with change subscription mechanism, makes one-way data flow design straight-forward. On your component, you simply need to subscribe the object and update the UI accordingly. On your action handler, you call performChanges(_:) and submit changes to Dflat without worrying about when update will be triggered. In real-world, this can be a bit more complicated because you want to merge some in-memory states when data propagate to the UI. Thus, the subscriber of object changes likely will be some components sit in the middle, i.e. a view model generator. This Combine s nicely with Rx programming paradigm. It also feels limiting that you don't control which thread the mutation happens. Dflat does expose some kind of control to you. You can set the targetQueue for SQLiteWorkspace . Anything beyond that, can only bite you in longer-term. You don't really want any of your queue to be blocked because some data persistence happening. As long as there is no coroutine support from Swift side, a completion callback is a necessary evil. Another criticism, which IMHO is more legit, is the lack of projection support. You can absolutely join tables by cleverly use fetchWithinASnapshot . But projection, i.e. only selecting a few columns to fetch, can be helpful, especially on Android, where object creation is more expensive (it doesn't help much on data fetching from disk unless all you fetch is covered by index ). This is doable thanks to flatbuffers' zero-copy implementation. However, it requires a rather different syntax on the IDL (interface description language) to describe the projection concisely. Something like: table Title <- BlogPost { permalink <- BlogPost.permalink title <- BlogPost.title } May work, and we can generate the corresponding Title object. It just diverges too much from flatbuffers schema to justify the learning curve at the moment.","title":"Features &amp; Trade Offs"},{"location":"notes/upgrade/","text":"Schema Upgrade \u00b6 In Schema Evolution , we briefly touched the general rules of schema upgrade. To be more precise, this note will discuss the exact rules with examples. Consider a relatively simple schema: table TextContent { text : string ; } union Content { TextContent } table BlogPost { title : string ( primary ); datetime : int ; content : Content ; } root_type BlogPost ; It is OK to change names of any property, append new fields to the end and deprecate old field. However, you cannot change types of a field, or move them around. table TextContent { text : string ( deprecated ); attributedText : string ; } table ImageContent { images : [ string ] ; } union Content { TextContent , ImageContent } table BlogPost { permalink : string ( primary ); datetime : int ( deprecated ); multimediaContent : Content ; title : string ( indexed ); unixTime : ulong ; } root_type BlogPost ; As much different as the schemas looked, they are compatible. You can upgrade / downgrade them from one to another because they follow the rules . In addition, remember: you can rename a primary key, but you cannot change or add a primary key. I may write a compatibility checker in the future, since rules can be more nuanced.","title":"Schema Upgrade"},{"location":"notes/upgrade/#schema-upgrade","text":"In Schema Evolution , we briefly touched the general rules of schema upgrade. To be more precise, this note will discuss the exact rules with examples. Consider a relatively simple schema: table TextContent { text : string ; } union Content { TextContent } table BlogPost { title : string ( primary ); datetime : int ; content : Content ; } root_type BlogPost ; It is OK to change names of any property, append new fields to the end and deprecate old field. However, you cannot change types of a field, or move them around. table TextContent { text : string ( deprecated ); attributedText : string ; } table ImageContent { images : [ string ] ; } union Content { TextContent , ImageContent } table BlogPost { permalink : string ( primary ); datetime : int ( deprecated ); multimediaContent : Content ; title : string ( indexed ); unixTime : ulong ; } root_type BlogPost ; As much different as the schemas looked, they are compatible. You can upgrade / downgrade them from one to another because they follow the rules . In addition, remember: you can rename a primary key, but you cannot change or add a primary key. I may write a compatibility checker in the future, since rules can be more nuanced.","title":"Schema Upgrade"},{"location":"reference/SQLiteWorkspace/","text":"CLASS SQLiteWorkspace \u00b6 public final class SQLiteWorkspace : Workspace Methods \u00b6 init(filePath:fileProtectionLevel:synchronous:writeConcurrency:targetQueue:) \u00b6 public required init ( filePath : String , fileProtectionLevel : FileProtectionLevel , synchronous : Synchronous = . normal , writeConcurrency : WriteConcurrency = . concurrent , targetQueue : DispatchQueue ? = nil ) Return a SQLite backed Workspace instance. Parameters: filePath: The path to the SQLite file. There will be 3 files named filePath, \"(filePath)-wal\" and \"(filePath)-shm\" created. fileProtectionLevel: The expected protection level for the database file. synchronous: The SQLite synchronous mode, read: https://www.sqlite.org/wal.html#performance_considerations writeConcurrency: Either .concurrent or .serial . targetQueue: If nil, we will create a queue based on writeConcurrency settings. If you supply your own queue, please read about WriteConcurrency before proceed. Parameters \u00b6 Name Description filePath The path to the SQLite file. There will be 3 files named filePath, \u201c(filePath)-wal\u201d and \u201c(filePath)-shm\u201d created. fileProtectionLevel The expected protection level for the database file. synchronous The SQLite synchronous mode, read: https://www.sqlite.org/wal.html#performance_considerations writeConcurrency Either .concurrent or .serial . targetQueue If nil, we will create a queue based on writeConcurrency settings. If you supply your own queue, please read about WriteConcurrency before proceed. shutdown(completion:) \u00b6 public func shutdown ( completion : (() -> Void )?) performChanges(_:changesHandler:completionHandler:) \u00b6 public func performChanges ( _ transactionalObjectTypes : [ Any . Type ], changesHandler : @ escaping Workspace . ChangesHandler , completionHandler : Workspace . CompletionHandler ? = nil ) Parameters \u00b6 Name Description transactionalObjectTypes A list of object types you are going to transact with. If you If you fetch or mutation an object outside of this list, it will fatal. changesHandler The transaction closure where you will give a transactionContext and safe to do data mutations through submission of change requests. completionHandler If supplied, will be called once the transaction committed. It will be called with success / failure. You don\u2019t need to handle failure cases specifically (such as retry), but rather to surface and log such error. fetch(for:) \u00b6 public func fetch < Element : Atom >( for ofType : Element . Type ) -> QueryBuilder < Element > fetchWithinASnapshot(_:) \u00b6 public func fetchWithinASnapshot < T >( _ closure : () -> T ) -> T subscribe(fetchedResult:changeHandler:) \u00b6 public func subscribe < Element : Atom >( fetchedResult : FetchedResult < Element >, changeHandler : @ escaping ( _ : FetchedResult < Element >) -> Void ) -> Workspace . Subscription where Element : Equatable Parameters \u00b6 Name Description fetchedResult The original fetchedResult. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed. subscribe(object:changeHandler:) \u00b6 public func subscribe < Element : Atom >( object : Element , changeHandler : @ escaping ( _ : SubscribedObject < Element >) -> Void ) -> Workspace . Subscription where Element : Equatable Parameters \u00b6 Name Description object The object to be observed. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed. publisher(for:) \u00b6 public func publisher < Element : Atom >( for object : Element ) -> AtomPublisher < Element > where Element : Equatable publisher(for:) \u00b6 public func publisher < Element : Atom >( for fetchedResult : FetchedResult < Element >) -> FetchedResultPublisher < Element > where Element : Equatable publisher(for:) \u00b6 public func publisher < Element : Atom >( for : Element . Type ) -> QueryPublisherBuilder < Element > where Element : Equatable ENUM SQLiteWorkspace.FileProtectionLevel \u00b6 public enum FileProtectionLevel : Int32 Cases \u00b6 noProtection \u00b6 case noProtection = 4 Class D: No protection. If the device is booted, in theory, you can access the content. When it is not booted, the content is protected by the Secure Enclave's hardware key. completeFileProtection \u00b6 case completeFileProtection = 1 Class A: The file is accessible if the phone is unlocked and the app is in foreground. You will lose the file access if the app is backgrounded or the phone is locked. completeFileProtectionUnlessOpen \u00b6 case completeFileProtectionUnlessOpen = 2 Class B: The file is accessible if the phone is unlocked. You will lose the file access if the phone is locked. completeFileProtectionUntilFirstUserAuthentication \u00b6 case completeFileProtectionUntilFirstUserAuthentication = 3 Class C: The file is accessible once user unlocked the phone once. The file cannot be accessed prior to that. For example, if you received a notification before first device unlock, the underlying database cannot be open successfully. ENUM SQLiteWorkspace.WriteConcurrency \u00b6 public enum WriteConcurrency Cases \u00b6 concurrent \u00b6 case concurrent Enable strict serializable multi-writer / multi-reader mode. Note that SQLite under the hood still writes serially. It only means the transaction closures can be executed concurrently. If you provided a targetQueue, please make sure it is a concurrent queue otherwise it will still execute transaction closure serially. The targetQueue is supplied by you, should be at reasonable priority, at least .default , because it sets the ceiling for any sub-queues targeting that, and we may need to bump the sub-queues depending on where you performChanges . serial \u00b6 case serial Enable single-writer / multi-reader mode. This will execute transaction closures serially. If you supply a targetQueue, please make sure it is serial. It is safe for this serial queue to have lower priority such as .utility , because we can bump the priority based on where you call performChanges . ENUM SQLiteWorkspace.Synchronous \u00b6 public enum Synchronous The synchronous mode of SQLite. We defaults to .normal . Read more on: https://www.sqlite.org/wal.html#performance_considerations Cases \u00b6 normal \u00b6 case normal full \u00b6 case full","title":"SQLiteWorkspace"},{"location":"reference/SQLiteWorkspace/#sqliteworkspace","text":"public final class SQLiteWorkspace : Workspace","title":"SQLiteWorkspace"},{"location":"reference/SQLiteWorkspace/#methods","text":"","title":"Methods"},{"location":"reference/SQLiteWorkspace/#initfilepathfileprotectionlevelsynchronouswriteconcurrencytargetqueue","text":"public required init ( filePath : String , fileProtectionLevel : FileProtectionLevel , synchronous : Synchronous = . normal , writeConcurrency : WriteConcurrency = . concurrent , targetQueue : DispatchQueue ? = nil ) Return a SQLite backed Workspace instance. Parameters: filePath: The path to the SQLite file. There will be 3 files named filePath, \"(filePath)-wal\" and \"(filePath)-shm\" created. fileProtectionLevel: The expected protection level for the database file. synchronous: The SQLite synchronous mode, read: https://www.sqlite.org/wal.html#performance_considerations writeConcurrency: Either .concurrent or .serial . targetQueue: If nil, we will create a queue based on writeConcurrency settings. If you supply your own queue, please read about WriteConcurrency before proceed.","title":"init(filePath:fileProtectionLevel:synchronous:writeConcurrency:targetQueue:)"},{"location":"reference/SQLiteWorkspace/#parameters","text":"Name Description filePath The path to the SQLite file. There will be 3 files named filePath, \u201c(filePath)-wal\u201d and \u201c(filePath)-shm\u201d created. fileProtectionLevel The expected protection level for the database file. synchronous The SQLite synchronous mode, read: https://www.sqlite.org/wal.html#performance_considerations writeConcurrency Either .concurrent or .serial . targetQueue If nil, we will create a queue based on writeConcurrency settings. If you supply your own queue, please read about WriteConcurrency before proceed.","title":"Parameters"},{"location":"reference/SQLiteWorkspace/#shutdowncompletion","text":"public func shutdown ( completion : (() -> Void )?)","title":"shutdown(completion:)"},{"location":"reference/SQLiteWorkspace/#performchanges_changeshandlercompletionhandler","text":"public func performChanges ( _ transactionalObjectTypes : [ Any . Type ], changesHandler : @ escaping Workspace . ChangesHandler , completionHandler : Workspace . CompletionHandler ? = nil )","title":"performChanges(_:changesHandler:completionHandler:)"},{"location":"reference/SQLiteWorkspace/#parameters_1","text":"Name Description transactionalObjectTypes A list of object types you are going to transact with. If you If you fetch or mutation an object outside of this list, it will fatal. changesHandler The transaction closure where you will give a transactionContext and safe to do data mutations through submission of change requests. completionHandler If supplied, will be called once the transaction committed. It will be called with success / failure. You don\u2019t need to handle failure cases specifically (such as retry), but rather to surface and log such error.","title":"Parameters"},{"location":"reference/SQLiteWorkspace/#fetchfor","text":"public func fetch < Element : Atom >( for ofType : Element . Type ) -> QueryBuilder < Element >","title":"fetch(for:)"},{"location":"reference/SQLiteWorkspace/#fetchwithinasnapshot_","text":"public func fetchWithinASnapshot < T >( _ closure : () -> T ) -> T","title":"fetchWithinASnapshot(_:)"},{"location":"reference/SQLiteWorkspace/#subscribefetchedresultchangehandler","text":"public func subscribe < Element : Atom >( fetchedResult : FetchedResult < Element >, changeHandler : @ escaping ( _ : FetchedResult < Element >) -> Void ) -> Workspace . Subscription where Element : Equatable","title":"subscribe(fetchedResult:changeHandler:)"},{"location":"reference/SQLiteWorkspace/#parameters_2","text":"Name Description fetchedResult The original fetchedResult. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed.","title":"Parameters"},{"location":"reference/SQLiteWorkspace/#subscribeobjectchangehandler","text":"public func subscribe < Element : Atom >( object : Element , changeHandler : @ escaping ( _ : SubscribedObject < Element >) -> Void ) -> Workspace . Subscription where Element : Equatable","title":"subscribe(object:changeHandler:)"},{"location":"reference/SQLiteWorkspace/#parameters_3","text":"Name Description object The object to be observed. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed.","title":"Parameters"},{"location":"reference/SQLiteWorkspace/#publisherfor","text":"public func publisher < Element : Atom >( for object : Element ) -> AtomPublisher < Element > where Element : Equatable","title":"publisher(for:)"},{"location":"reference/SQLiteWorkspace/#publisherfor_1","text":"public func publisher < Element : Atom >( for fetchedResult : FetchedResult < Element >) -> FetchedResultPublisher < Element > where Element : Equatable","title":"publisher(for:)"},{"location":"reference/SQLiteWorkspace/#publisherfor_2","text":"public func publisher < Element : Atom >( for : Element . Type ) -> QueryPublisherBuilder < Element > where Element : Equatable ENUM","title":"publisher(for:)"},{"location":"reference/SQLiteWorkspace/#sqliteworkspacefileprotectionlevel","text":"public enum FileProtectionLevel : Int32","title":"SQLiteWorkspace.FileProtectionLevel"},{"location":"reference/SQLiteWorkspace/#cases","text":"","title":"Cases"},{"location":"reference/SQLiteWorkspace/#noprotection","text":"case noProtection = 4 Class D: No protection. If the device is booted, in theory, you can access the content. When it is not booted, the content is protected by the Secure Enclave's hardware key.","title":"noProtection"},{"location":"reference/SQLiteWorkspace/#completefileprotection","text":"case completeFileProtection = 1 Class A: The file is accessible if the phone is unlocked and the app is in foreground. You will lose the file access if the app is backgrounded or the phone is locked.","title":"completeFileProtection"},{"location":"reference/SQLiteWorkspace/#completefileprotectionunlessopen","text":"case completeFileProtectionUnlessOpen = 2 Class B: The file is accessible if the phone is unlocked. You will lose the file access if the phone is locked.","title":"completeFileProtectionUnlessOpen"},{"location":"reference/SQLiteWorkspace/#completefileprotectionuntilfirstuserauthentication","text":"case completeFileProtectionUntilFirstUserAuthentication = 3 Class C: The file is accessible once user unlocked the phone once. The file cannot be accessed prior to that. For example, if you received a notification before first device unlock, the underlying database cannot be open successfully. ENUM","title":"completeFileProtectionUntilFirstUserAuthentication"},{"location":"reference/SQLiteWorkspace/#sqliteworkspacewriteconcurrency","text":"public enum WriteConcurrency","title":"SQLiteWorkspace.WriteConcurrency"},{"location":"reference/SQLiteWorkspace/#cases_1","text":"","title":"Cases"},{"location":"reference/SQLiteWorkspace/#concurrent","text":"case concurrent Enable strict serializable multi-writer / multi-reader mode. Note that SQLite under the hood still writes serially. It only means the transaction closures can be executed concurrently. If you provided a targetQueue, please make sure it is a concurrent queue otherwise it will still execute transaction closure serially. The targetQueue is supplied by you, should be at reasonable priority, at least .default , because it sets the ceiling for any sub-queues targeting that, and we may need to bump the sub-queues depending on where you performChanges .","title":"concurrent"},{"location":"reference/SQLiteWorkspace/#serial","text":"case serial Enable single-writer / multi-reader mode. This will execute transaction closures serially. If you supply a targetQueue, please make sure it is serial. It is safe for this serial queue to have lower priority such as .utility , because we can bump the priority based on where you call performChanges . ENUM","title":"serial"},{"location":"reference/SQLiteWorkspace/#sqliteworkspacesynchronous","text":"public enum Synchronous The synchronous mode of SQLite. We defaults to .normal . Read more on: https://www.sqlite.org/wal.html#performance_considerations","title":"SQLiteWorkspace.Synchronous"},{"location":"reference/SQLiteWorkspace/#cases_2","text":"","title":"Cases"},{"location":"reference/SQLiteWorkspace/#normal","text":"case normal","title":"normal"},{"location":"reference/SQLiteWorkspace/#full","text":"case full","title":"full"},{"location":"reference/TransactionContext/","text":"PROTOCOL TransactionContext \u00b6 public protocol TransactionContext Methods \u00b6 submit(_:) \u00b6 func submit ( _ : ChangeRequest ) throws -> UpdatedObject Submit a change request in a transaction. The change will be available immediately inside this transaction and will be available once the transaction closure is done to everyone outside of the transaction closure. It throws a TransactionError if there are errors. Otherwise, return UpdatedObject to denote whether you inserted, updated or deleted an object. abort() \u00b6 func abort () -> Bool Abort the current transaction. This will cause whatever happened inside the current transaction to rollback immediately, and anything submitted after abort will throw TransactionError.aborted error. EXTENSION TransactionContext \u00b6 public extension TransactionContext Methods \u00b6 try(submit:) \u00b6 func ` try `( submit changeRequest : ChangeRequest ) -> UpdatedObject ? Convenient method for submit change request. submit() may throw exceptions, but try(submit:) will not. Rather, it will fatal in case of TransactionError.objectAlreadyExists . For any other types of TransactionError , it will simply return nil. ENUM TransactionError \u00b6 public enum TransactionError : Error Cases \u00b6 aborted \u00b6 case aborted The transaction has been aborted already before submitting the request. objectAlreadyExists \u00b6 case objectAlreadyExists The object already exists. Conflict on either primary keys or unique properties. diskFull \u00b6 case diskFull We will rollback the whole transaction in case of disk full. others \u00b6 case others Other types of errors, in these cases, we will simply rollback the whole transaction.","title":"TransactionContext"},{"location":"reference/TransactionContext/#transactioncontext","text":"public protocol TransactionContext","title":"TransactionContext"},{"location":"reference/TransactionContext/#methods","text":"","title":"Methods"},{"location":"reference/TransactionContext/#submit_","text":"func submit ( _ : ChangeRequest ) throws -> UpdatedObject Submit a change request in a transaction. The change will be available immediately inside this transaction and will be available once the transaction closure is done to everyone outside of the transaction closure. It throws a TransactionError if there are errors. Otherwise, return UpdatedObject to denote whether you inserted, updated or deleted an object.","title":"submit(_:)"},{"location":"reference/TransactionContext/#abort","text":"func abort () -> Bool Abort the current transaction. This will cause whatever happened inside the current transaction to rollback immediately, and anything submitted after abort will throw TransactionError.aborted error. EXTENSION","title":"abort()"},{"location":"reference/TransactionContext/#transactioncontext_1","text":"public extension TransactionContext","title":"TransactionContext"},{"location":"reference/TransactionContext/#methods_1","text":"","title":"Methods"},{"location":"reference/TransactionContext/#trysubmit","text":"func ` try `( submit changeRequest : ChangeRequest ) -> UpdatedObject ? Convenient method for submit change request. submit() may throw exceptions, but try(submit:) will not. Rather, it will fatal in case of TransactionError.objectAlreadyExists . For any other types of TransactionError , it will simply return nil. ENUM","title":"try(submit:)"},{"location":"reference/TransactionContext/#transactionerror","text":"public enum TransactionError : Error","title":"TransactionError"},{"location":"reference/TransactionContext/#cases","text":"","title":"Cases"},{"location":"reference/TransactionContext/#aborted","text":"case aborted The transaction has been aborted already before submitting the request.","title":"aborted"},{"location":"reference/TransactionContext/#objectalreadyexists","text":"case objectAlreadyExists The object already exists. Conflict on either primary keys or unique properties.","title":"objectAlreadyExists"},{"location":"reference/TransactionContext/#diskfull","text":"case diskFull We will rollback the whole transaction in case of disk full.","title":"diskFull"},{"location":"reference/TransactionContext/#others","text":"case others Other types of errors, in these cases, we will simply rollback the whole transaction.","title":"others"},{"location":"reference/Workspace/","text":"PROTOCOL Queryable \u00b6 public protocol Queryable Methods \u00b6 fetch(for:) \u00b6 func fetch < Element : Atom >( for ofType : Element . Type ) -> QueryBuilder < Element > Return a QueryBuilder that you can make where or all queries against. fetchWithinASnapshot(_:) \u00b6 func fetchWithinASnapshot < T >( _ : () -> T ) -> T Provide a consistent view for fetching multiple objects at once. PROTOCOL Workspace \u00b6 public protocol Workspace : Queryable Methods \u00b6 shutdown(completion:) \u00b6 func shutdown ( completion : (() -> Void )?) Shutdown the Workspace. All transactions made to Dflat after this call will fail. Transactions initiated before this will finish normally. Data fetching after this will return empty results. Any data fetching triggered before this call will finish normally, hence the completion part. The completion closure, if supplied, will be called once all transactions and data fetching initiated before shutdown finish. performChanges(_:changesHandler:completionHandler:) \u00b6 func performChanges ( _ transactionalObjectTypes : [ Any . Type ], changesHandler : @ escaping ChangesHandler , completionHandler : CompletionHandler ?) Perform a transaction for given object types. Parameters: transactionalObjectTypes: A list of object types you are going to transact with. If you If you fetch or mutation an object outside of this list, it will fatal. changesHandler: The transaction closure where you will give a transactionContext and safe to do data mutations through submission of change requests. completionHandler: If supplied, will be called once the transaction committed. It will be called with success / failure. You don't need to handle failure cases specifically (such as retry), but rather to surface and log such error. Parameters \u00b6 Name Description transactionalObjectTypes A list of object types you are going to transact with. If you If you fetch or mutation an object outside of this list, it will fatal. changesHandler The transaction closure where you will give a transactionContext and safe to do data mutations through submission of change requests. completionHandler If supplied, will be called once the transaction committed. It will be called with success / failure. You don\u2019t need to handle failure cases specifically (such as retry), but rather to surface and log such error. subscribe(fetchedResult:changeHandler:) \u00b6 func subscribe < Element : Atom >( fetchedResult : FetchedResult < Element >, changeHandler : @ escaping ( _ : FetchedResult < Element >) -> Void ) -> Subscription where Element : Equatable Subscribe to changes of a fetched result. You queries fetched result with fetch(for:).where() method and the result can be observed. If any object created / updated meet the query criterion, the callback will happen and you will get a updated fetched result. Parameters: fetchedResult: The original fetchedResult. If it is outdated already, you will get an updated callback soon after. changeHandler: The callback where you will receive an update if anything changed. Returns: A subscription object that you can cancel the subscription. If no one hold the subscription object, it will cancel automatically. Parameters \u00b6 Name Description fetchedResult The original fetchedResult. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed. subscribe(object:changeHandler:) \u00b6 func subscribe < Element : Atom >( object : Element , changeHandler : @ escaping ( _ : SubscribedObject < Element >) -> Void ) -> Subscription where Element : Equatable Subscribe to changes of an object. If anything in the object changed or the object itself is deleted. Deletion is a terminal event for subscription. Even if later you inserted an object with the same primary key, the subscription callback won't be triggered. This is different from fetched result subscription above where if you query by primary key, you will get subscription update if a new object with the same primary key later created. Parameters: object: The object to be observed. If it is outdated already, you will get an updated callback soon after. changeHandler: The callback where you will receive an update if anything changed. Returns: A subscription object that you can cancel on. If no one hold the subscription, it will cancel automatically. Parameters \u00b6 Name Description object The object to be observed. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed. publisher(for:) \u00b6 func publisher < Element : Atom >( for : Element ) -> AtomPublisher < Element > where Element : Equatable Return a publisher for object subscription in Combine. publisher(for:) \u00b6 func publisher < Element : Atom >( for : FetchedResult < Element >) -> FetchedResultPublisher < Element > where Element : Equatable Return a publisher for fetched result subscription in Combine. publisher(for:) \u00b6 func publisher < Element : Atom >( for : Element . Type ) -> QueryPublisherBuilder < Element > where Element : Equatable Return a publisher builder for query subscription in Combine. CLASS QueryBuilder \u00b6 open class QueryBuilder < Element : Atom > Methods \u00b6 init() \u00b6 public init () where(_:limit:orderBy:) \u00b6 open func ` where `< T : Expr >( _ query : T , limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> FetchedResult < Element > where T . ResultType == Bool , T . Element == Element Make query against the Workspace. This is coupled with fetch(for:) method and shouldn't be used independently. Parameters: query: The query such as Post.title == \"some title\" && Post.color == .red limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: Return a fetched result which interacts just like normal array. Parameters \u00b6 Name Description query The query such as Post.title == \"some title\" && Post.color == .red limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending] all(limit:orderBy:) \u00b6 open func all ( limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> FetchedResult < Element > Return all objects for a class. Parameters: limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: Return a fetched result which interacts just like normal array. Parameters \u00b6 Name Description limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending] PROTOCOL WorkspaceSubscription \u00b6 public protocol WorkspaceSubscription Methods \u00b6 cancel() \u00b6 func cancel () Cancel an existing subscription. It is guaranteed that no callback will happen immediately after cancel . ENUM SubscribedObject \u00b6 public enum SubscribedObject < Element : Atom > Cases \u00b6 updated(_:) \u00b6 case updated ( _ : Element ) Giving the updated object. deleted \u00b6 case deleted The object is deleted. This denotes the end of a subscription. CLASS QueryPublisherBuilder \u00b6 open class QueryPublisherBuilder < Element : Atom > where Element : Equatable Methods \u00b6 init() \u00b6 public init () where(_:limit:orderBy:) \u00b6 open func ` where `< T : Expr >( _ query : T , limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> QueryPublisher < Element > where T . ResultType == Bool , T . Element == Element Subscribe to a query against the Workspace. This is coupled with publisher(for: Element.self) method and shouldn't be used independently. Parameters: query: The query such as Post.title == \"some title\" && Post.color == .red limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: A publisher object that can be interacted with Combine. Parameters \u00b6 Name Description query The query such as Post.title == \"some title\" && Post.color == .red limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending] all(limit:orderBy:) \u00b6 open func all ( limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> QueryPublisher < Element > Subscribe to all changes to a class. This is coupled with publisher(for: Element.self) method and shouldn't be used independently. Parameters: limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: A publisher object that can be interacted with Combine. Parameters \u00b6 Name Description limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending]","title":"Workspace"},{"location":"reference/Workspace/#queryable","text":"public protocol Queryable","title":"Queryable"},{"location":"reference/Workspace/#methods","text":"","title":"Methods"},{"location":"reference/Workspace/#fetchfor","text":"func fetch < Element : Atom >( for ofType : Element . Type ) -> QueryBuilder < Element > Return a QueryBuilder that you can make where or all queries against.","title":"fetch(for:)"},{"location":"reference/Workspace/#fetchwithinasnapshot_","text":"func fetchWithinASnapshot < T >( _ : () -> T ) -> T Provide a consistent view for fetching multiple objects at once. PROTOCOL","title":"fetchWithinASnapshot(_:)"},{"location":"reference/Workspace/#workspace","text":"public protocol Workspace : Queryable","title":"Workspace"},{"location":"reference/Workspace/#methods_1","text":"","title":"Methods"},{"location":"reference/Workspace/#shutdowncompletion","text":"func shutdown ( completion : (() -> Void )?) Shutdown the Workspace. All transactions made to Dflat after this call will fail. Transactions initiated before this will finish normally. Data fetching after this will return empty results. Any data fetching triggered before this call will finish normally, hence the completion part. The completion closure, if supplied, will be called once all transactions and data fetching initiated before shutdown finish.","title":"shutdown(completion:)"},{"location":"reference/Workspace/#performchanges_changeshandlercompletionhandler","text":"func performChanges ( _ transactionalObjectTypes : [ Any . Type ], changesHandler : @ escaping ChangesHandler , completionHandler : CompletionHandler ?) Perform a transaction for given object types. Parameters: transactionalObjectTypes: A list of object types you are going to transact with. If you If you fetch or mutation an object outside of this list, it will fatal. changesHandler: The transaction closure where you will give a transactionContext and safe to do data mutations through submission of change requests. completionHandler: If supplied, will be called once the transaction committed. It will be called with success / failure. You don't need to handle failure cases specifically (such as retry), but rather to surface and log such error.","title":"performChanges(_:changesHandler:completionHandler:)"},{"location":"reference/Workspace/#parameters","text":"Name Description transactionalObjectTypes A list of object types you are going to transact with. If you If you fetch or mutation an object outside of this list, it will fatal. changesHandler The transaction closure where you will give a transactionContext and safe to do data mutations through submission of change requests. completionHandler If supplied, will be called once the transaction committed. It will be called with success / failure. You don\u2019t need to handle failure cases specifically (such as retry), but rather to surface and log such error.","title":"Parameters"},{"location":"reference/Workspace/#subscribefetchedresultchangehandler","text":"func subscribe < Element : Atom >( fetchedResult : FetchedResult < Element >, changeHandler : @ escaping ( _ : FetchedResult < Element >) -> Void ) -> Subscription where Element : Equatable Subscribe to changes of a fetched result. You queries fetched result with fetch(for:).where() method and the result can be observed. If any object created / updated meet the query criterion, the callback will happen and you will get a updated fetched result. Parameters: fetchedResult: The original fetchedResult. If it is outdated already, you will get an updated callback soon after. changeHandler: The callback where you will receive an update if anything changed. Returns: A subscription object that you can cancel the subscription. If no one hold the subscription object, it will cancel automatically.","title":"subscribe(fetchedResult:changeHandler:)"},{"location":"reference/Workspace/#parameters_1","text":"Name Description fetchedResult The original fetchedResult. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed.","title":"Parameters"},{"location":"reference/Workspace/#subscribeobjectchangehandler","text":"func subscribe < Element : Atom >( object : Element , changeHandler : @ escaping ( _ : SubscribedObject < Element >) -> Void ) -> Subscription where Element : Equatable Subscribe to changes of an object. If anything in the object changed or the object itself is deleted. Deletion is a terminal event for subscription. Even if later you inserted an object with the same primary key, the subscription callback won't be triggered. This is different from fetched result subscription above where if you query by primary key, you will get subscription update if a new object with the same primary key later created. Parameters: object: The object to be observed. If it is outdated already, you will get an updated callback soon after. changeHandler: The callback where you will receive an update if anything changed. Returns: A subscription object that you can cancel on. If no one hold the subscription, it will cancel automatically.","title":"subscribe(object:changeHandler:)"},{"location":"reference/Workspace/#parameters_2","text":"Name Description object The object to be observed. If it is outdated already, you will get an updated callback soon after. changeHandler The callback where you will receive an update if anything changed.","title":"Parameters"},{"location":"reference/Workspace/#publisherfor","text":"func publisher < Element : Atom >( for : Element ) -> AtomPublisher < Element > where Element : Equatable Return a publisher for object subscription in Combine.","title":"publisher(for:)"},{"location":"reference/Workspace/#publisherfor_1","text":"func publisher < Element : Atom >( for : FetchedResult < Element >) -> FetchedResultPublisher < Element > where Element : Equatable Return a publisher for fetched result subscription in Combine.","title":"publisher(for:)"},{"location":"reference/Workspace/#publisherfor_2","text":"func publisher < Element : Atom >( for : Element . Type ) -> QueryPublisherBuilder < Element > where Element : Equatable Return a publisher builder for query subscription in Combine. CLASS","title":"publisher(for:)"},{"location":"reference/Workspace/#querybuilder","text":"open class QueryBuilder < Element : Atom >","title":"QueryBuilder"},{"location":"reference/Workspace/#methods_2","text":"","title":"Methods"},{"location":"reference/Workspace/#init","text":"public init ()","title":"init()"},{"location":"reference/Workspace/#where_limitorderby","text":"open func ` where `< T : Expr >( _ query : T , limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> FetchedResult < Element > where T . ResultType == Bool , T . Element == Element Make query against the Workspace. This is coupled with fetch(for:) method and shouldn't be used independently. Parameters: query: The query such as Post.title == \"some title\" && Post.color == .red limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: Return a fetched result which interacts just like normal array.","title":"where(_:limit:orderBy:)"},{"location":"reference/Workspace/#parameters_3","text":"Name Description query The query such as Post.title == \"some title\" && Post.color == .red limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending]","title":"Parameters"},{"location":"reference/Workspace/#alllimitorderby","text":"open func all ( limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> FetchedResult < Element > Return all objects for a class. Parameters: limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: Return a fetched result which interacts just like normal array.","title":"all(limit:orderBy:)"},{"location":"reference/Workspace/#parameters_4","text":"Name Description limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending] PROTOCOL","title":"Parameters"},{"location":"reference/Workspace/#workspacesubscription","text":"public protocol WorkspaceSubscription","title":"WorkspaceSubscription"},{"location":"reference/Workspace/#methods_3","text":"","title":"Methods"},{"location":"reference/Workspace/#cancel","text":"func cancel () Cancel an existing subscription. It is guaranteed that no callback will happen immediately after cancel . ENUM","title":"cancel()"},{"location":"reference/Workspace/#subscribedobject","text":"public enum SubscribedObject < Element : Atom >","title":"SubscribedObject"},{"location":"reference/Workspace/#cases","text":"","title":"Cases"},{"location":"reference/Workspace/#updated_","text":"case updated ( _ : Element ) Giving the updated object.","title":"updated(_:)"},{"location":"reference/Workspace/#deleted","text":"case deleted The object is deleted. This denotes the end of a subscription. CLASS","title":"deleted"},{"location":"reference/Workspace/#querypublisherbuilder","text":"open class QueryPublisherBuilder < Element : Atom > where Element : Equatable","title":"QueryPublisherBuilder"},{"location":"reference/Workspace/#methods_4","text":"","title":"Methods"},{"location":"reference/Workspace/#init_1","text":"public init ()","title":"init()"},{"location":"reference/Workspace/#where_limitorderby_1","text":"open func ` where `< T : Expr >( _ query : T , limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> QueryPublisher < Element > where T . ResultType == Bool , T . Element == Element Subscribe to a query against the Workspace. This is coupled with publisher(for: Element.self) method and shouldn't be used independently. Parameters: query: The query such as Post.title == \"some title\" && Post.color == .red limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: A publisher object that can be interacted with Combine.","title":"where(_:limit:orderBy:)"},{"location":"reference/Workspace/#parameters_5","text":"Name Description query The query such as Post.title == \"some title\" && Post.color == .red limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending]","title":"Parameters"},{"location":"reference/Workspace/#alllimitorderby_1","text":"open func all ( limit : Limit = . noLimit , orderBy : [ OrderBy < Element >] = []) -> QueryPublisher < Element > Subscribe to all changes to a class. This is coupled with publisher(for: Element.self) method and shouldn't be used independently. Parameters: limit: The limit. Default to .noLimit , you can supply .limit(number) orderBy: The array of keys to order the result. Such as [Post.priority.descending] Returns: A publisher object that can be interacted with Combine.","title":"all(limit:orderBy:)"},{"location":"reference/Workspace/#parameters_6","text":"Name Description limit The limit. Default to .noLimit , you can supply .limit(number) orderBy The array of keys to order the result. Such as [Post.priority.descending]","title":"Parameters"}]}